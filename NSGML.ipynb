{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import keras\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = plt.get_cmap('inferno')\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "for g in genres:\n",
    "    pathlib.Path(f'img_data/{g}').mkdir(parents=True, exist_ok=True)     \n",
    "    for filename in os.listdir(f'C:/Users/nigel/Desktop/NSG ML/genres/{g}'):\n",
    "        songname = f'C:/Users/nigel/Desktop/NSG ML/genres/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "        plt.axis('off');\n",
    "        plt.savefig(f'img_data/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "for i in range(1, 21):\n",
    "    header += f' mfcc{i}'\n",
    "header += ' label'\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "for g in genres:\n",
    "    for filename in os.listdir(f'C:/Users/nigel/Desktop/NSG ML/genres/{g}'):\n",
    "        songname = f'C:/Users/nigel/Desktop/NSG ML/genres/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=30)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        rmse = librosa.feature.rmse(y=y)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        to_append += f' {g}'\n",
    "        file = open('data.csv', 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rmse</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00000.au</td>\n",
       "      <td>0.349943</td>\n",
       "      <td>0.130225</td>\n",
       "      <td>1784.420446</td>\n",
       "      <td>2002.650192</td>\n",
       "      <td>3806.485316</td>\n",
       "      <td>0.083066</td>\n",
       "      <td>-113.596742</td>\n",
       "      <td>121.557302</td>\n",
       "      <td>-19.158825</td>\n",
       "      <td>...</td>\n",
       "      <td>8.810668</td>\n",
       "      <td>-3.667367</td>\n",
       "      <td>5.751690</td>\n",
       "      <td>-5.162761</td>\n",
       "      <td>0.750947</td>\n",
       "      <td>-1.691937</td>\n",
       "      <td>-0.409954</td>\n",
       "      <td>-2.300208</td>\n",
       "      <td>1.219928</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00001.au</td>\n",
       "      <td>0.340983</td>\n",
       "      <td>0.095918</td>\n",
       "      <td>1529.835316</td>\n",
       "      <td>2038.617579</td>\n",
       "      <td>3548.820207</td>\n",
       "      <td>0.056044</td>\n",
       "      <td>-207.556796</td>\n",
       "      <td>124.006717</td>\n",
       "      <td>8.930562</td>\n",
       "      <td>...</td>\n",
       "      <td>5.376802</td>\n",
       "      <td>-2.239119</td>\n",
       "      <td>4.216963</td>\n",
       "      <td>-6.012273</td>\n",
       "      <td>0.936109</td>\n",
       "      <td>-0.716537</td>\n",
       "      <td>0.293875</td>\n",
       "      <td>-0.287431</td>\n",
       "      <td>0.531573</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00002.au</td>\n",
       "      <td>0.363603</td>\n",
       "      <td>0.175573</td>\n",
       "      <td>1552.481958</td>\n",
       "      <td>1747.165985</td>\n",
       "      <td>3040.514948</td>\n",
       "      <td>0.076301</td>\n",
       "      <td>-90.754394</td>\n",
       "      <td>140.459907</td>\n",
       "      <td>-29.109965</td>\n",
       "      <td>...</td>\n",
       "      <td>5.789265</td>\n",
       "      <td>-8.905224</td>\n",
       "      <td>-1.083720</td>\n",
       "      <td>-9.218359</td>\n",
       "      <td>2.455805</td>\n",
       "      <td>-7.726901</td>\n",
       "      <td>-1.815724</td>\n",
       "      <td>-3.433434</td>\n",
       "      <td>-2.226821</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00003.au</td>\n",
       "      <td>0.404779</td>\n",
       "      <td>0.141191</td>\n",
       "      <td>1070.119953</td>\n",
       "      <td>1596.333948</td>\n",
       "      <td>2185.028454</td>\n",
       "      <td>0.033309</td>\n",
       "      <td>-199.431144</td>\n",
       "      <td>150.099218</td>\n",
       "      <td>5.647594</td>\n",
       "      <td>...</td>\n",
       "      <td>6.087676</td>\n",
       "      <td>-2.476420</td>\n",
       "      <td>-1.073890</td>\n",
       "      <td>-2.874777</td>\n",
       "      <td>0.780976</td>\n",
       "      <td>-3.316932</td>\n",
       "      <td>0.637981</td>\n",
       "      <td>-0.619690</td>\n",
       "      <td>-3.408233</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00004.au</td>\n",
       "      <td>0.308590</td>\n",
       "      <td>0.091563</td>\n",
       "      <td>1835.494603</td>\n",
       "      <td>1748.362448</td>\n",
       "      <td>3580.945013</td>\n",
       "      <td>0.101500</td>\n",
       "      <td>-160.266031</td>\n",
       "      <td>126.198800</td>\n",
       "      <td>-35.605448</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.806385</td>\n",
       "      <td>-6.934122</td>\n",
       "      <td>-7.558619</td>\n",
       "      <td>-9.173552</td>\n",
       "      <td>-4.512166</td>\n",
       "      <td>-5.453538</td>\n",
       "      <td>-0.924162</td>\n",
       "      <td>-4.409333</td>\n",
       "      <td>-11.703781</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename  chroma_stft      rmse  spectral_centroid  \\\n",
       "0  blues.00000.au     0.349943  0.130225        1784.420446   \n",
       "1  blues.00001.au     0.340983  0.095918        1529.835316   \n",
       "2  blues.00002.au     0.363603  0.175573        1552.481958   \n",
       "3  blues.00003.au     0.404779  0.141191        1070.119953   \n",
       "4  blues.00004.au     0.308590  0.091563        1835.494603   \n",
       "\n",
       "   spectral_bandwidth      rolloff  zero_crossing_rate       mfcc1  \\\n",
       "0         2002.650192  3806.485316            0.083066 -113.596742   \n",
       "1         2038.617579  3548.820207            0.056044 -207.556796   \n",
       "2         1747.165985  3040.514948            0.076301  -90.754394   \n",
       "3         1596.333948  2185.028454            0.033309 -199.431144   \n",
       "4         1748.362448  3580.945013            0.101500 -160.266031   \n",
       "\n",
       "        mfcc2      mfcc3  ...    mfcc12    mfcc13    mfcc14    mfcc15  \\\n",
       "0  121.557302 -19.158825  ...  8.810668 -3.667367  5.751690 -5.162761   \n",
       "1  124.006717   8.930562  ...  5.376802 -2.239119  4.216963 -6.012273   \n",
       "2  140.459907 -29.109965  ...  5.789265 -8.905224 -1.083720 -9.218359   \n",
       "3  150.099218   5.647594  ...  6.087676 -2.476420 -1.073890 -2.874777   \n",
       "4  126.198800 -35.605448  ... -2.806385 -6.934122 -7.558619 -9.173552   \n",
       "\n",
       "     mfcc16    mfcc17    mfcc18    mfcc19     mfcc20  label  \n",
       "0  0.750947 -1.691937 -0.409954 -2.300208   1.219928  blues  \n",
       "1  0.936109 -0.716537  0.293875 -0.287431   0.531573  blues  \n",
       "2  2.455805 -7.726901 -1.815724 -3.433434  -2.226821  blues  \n",
       "3  0.780976 -3.316932  0.637981 -0.619690  -3.408233  blues  \n",
       "4 -4.512166 -5.453538 -0.924162 -4.409333 -11.703781  blues  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['blues.00000.au', 0.3499431970389887, 0.13022463023662567, ...,\n",
       "        -2.3002080931099553, 1.219928131251096, 'blues'],\n",
       "       ['blues.00001.au', 0.340983161628006, 0.09591842442750932, ...,\n",
       "        -0.2874306648121582, 0.5315729228628573, 'blues'],\n",
       "       ['blues.00002.au', 0.363602838496103, 0.17557303607463834, ...,\n",
       "        -3.4334342717656465, -2.2268214410307183, 'blues'],\n",
       "       ...,\n",
       "       ['rock.00097.au', 0.4321034468964737, 0.08161668479442596, ...,\n",
       "        -12.594177514097485, -2.10700255491672, 'rock'],\n",
       "       ['rock.00098.au', 0.3623490158126501, 0.08388779312372208, ...,\n",
       "        -5.043121274989656, -3.5855956471307313, 'rock'],\n",
       "       ['rock.00099.au', 0.35819512534874665, 0.05446073040366173, ...,\n",
       "        -2.0220346710460277, 1.158525253018968, 'rock']], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unneccesary columns\n",
    "data = data.drop(['filename'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(genre_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.35174862, -0.01072298, -0.58330334, ..., -0.23719158,\n",
       "         0.00761145,  0.60349813],\n",
       "       [-0.46146578, -0.53326615, -0.93906628, ..., -0.05518978,\n",
       "         0.5438236 ,  0.42403528],\n",
       "       [-0.18448399,  0.68001209, -0.90741936, ..., -0.60070707,\n",
       "        -0.29428464, -0.29511278],\n",
       "       ...,\n",
       "       [ 0.65431762, -0.75110651, -0.17418012, ...,  0.76028053,\n",
       "        -2.73474414, -0.26387449],\n",
       "       [-0.19983726, -0.71651358, -1.12235633, ...,  0.2717664 ,\n",
       "        -0.72311185, -0.64936228],\n",
       "       [-0.25070236, -1.16473892, -0.82782084, ..., -0.12506872,\n",
       "         0.08171799,  0.58748963]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.39449724,  1.47060174,  0.98545433,  0.25140643,  0.60221307,\n",
       "        1.6496682 ,  1.49161158, -0.78238686, -0.72901394,  1.24332047,\n",
       "       -1.68895741,  0.96325771, -0.74780876,  0.69948674, -0.39118402,\n",
       "        1.37015953, -1.02585361,  2.15765235, -0.79324632,  1.91273361,\n",
       "       -0.69639818,  1.43828371, -0.31295742,  0.74952739, -1.22694914,\n",
       "        1.99215478])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = X_train[:200]\n",
    "partial_x_train = X_train[200:]\n",
    "\n",
    "y_val = y_train[:200]\n",
    "partial_y_train = y_train[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nigel\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 600 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.9742 - acc: 0.3067 - val_loss: 1.6498 - val_acc: 0.4400\n",
      "Epoch 2/200\n",
      "600/600 [==============================] - 0s 415us/step - loss: 1.4841 - acc: 0.4633 - val_loss: 1.4962 - val_acc: 0.4250\n",
      "Epoch 3/200\n",
      "600/600 [==============================] - 0s 375us/step - loss: 1.2298 - acc: 0.5583 - val_loss: 1.2297 - val_acc: 0.5600\n",
      "Epoch 4/200\n",
      "600/600 [==============================] - 0s 374us/step - loss: 1.0053 - acc: 0.6217 - val_loss: 1.1211 - val_acc: 0.6000\n",
      "Epoch 5/200\n",
      "600/600 [==============================] - 0s 401us/step - loss: 0.8621 - acc: 0.7183 - val_loss: 1.1440 - val_acc: 0.6000\n",
      "Epoch 6/200\n",
      "600/600 [==============================] - 0s 363us/step - loss: 0.7373 - acc: 0.7317 - val_loss: 1.0127 - val_acc: 0.6500\n",
      "Epoch 7/200\n",
      "600/600 [==============================] - 0s 387us/step - loss: 0.6297 - acc: 0.7683 - val_loss: 1.0601 - val_acc: 0.6450\n",
      "Epoch 8/200\n",
      "600/600 [==============================] - 0s 383us/step - loss: 0.6292 - acc: 0.7800 - val_loss: 0.9841 - val_acc: 0.6650\n",
      "Epoch 9/200\n",
      "600/600 [==============================] - 0s 407us/step - loss: 0.4884 - acc: 0.8383 - val_loss: 1.0114 - val_acc: 0.6850\n",
      "Epoch 10/200\n",
      "600/600 [==============================] - 0s 392us/step - loss: 0.4113 - acc: 0.8550 - val_loss: 0.9931 - val_acc: 0.7000\n",
      "Epoch 11/200\n",
      "600/600 [==============================] - 0s 375us/step - loss: 0.3463 - acc: 0.8850 - val_loss: 1.1041 - val_acc: 0.6450\n",
      "Epoch 12/200\n",
      "600/600 [==============================] - 0s 449us/step - loss: 0.3256 - acc: 0.8967 - val_loss: 1.0692 - val_acc: 0.6400\n",
      "Epoch 13/200\n",
      "600/600 [==============================] - 0s 357us/step - loss: 0.2757 - acc: 0.9150 - val_loss: 1.1105 - val_acc: 0.6600\n",
      "Epoch 14/200\n",
      "600/600 [==============================] - 0s 349us/step - loss: 0.2713 - acc: 0.9167 - val_loss: 1.0221 - val_acc: 0.6550\n",
      "Epoch 15/200\n",
      "600/600 [==============================] - 0s 357us/step - loss: 0.2305 - acc: 0.9350 - val_loss: 1.0920 - val_acc: 0.6650\n",
      "Epoch 16/200\n",
      "600/600 [==============================] - 0s 397us/step - loss: 0.1639 - acc: 0.9600 - val_loss: 1.0776 - val_acc: 0.6550\n",
      "Epoch 17/200\n",
      "600/600 [==============================] - 0s 371us/step - loss: 0.1150 - acc: 0.9733 - val_loss: 1.1801 - val_acc: 0.6500\n",
      "Epoch 18/200\n",
      "600/600 [==============================] - 0s 443us/step - loss: 0.0927 - acc: 0.9833 - val_loss: 1.1664 - val_acc: 0.6600\n",
      "Epoch 19/200\n",
      "600/600 [==============================] - 0s 368us/step - loss: 0.0919 - acc: 0.9783 - val_loss: 1.3128 - val_acc: 0.6400\n",
      "Epoch 20/200\n",
      "600/600 [==============================] - 0s 374us/step - loss: 0.1608 - acc: 0.9533 - val_loss: 1.2212 - val_acc: 0.6350\n",
      "Epoch 21/200\n",
      "600/600 [==============================] - 0s 356us/step - loss: 0.1654 - acc: 0.9450 - val_loss: 1.2515 - val_acc: 0.6700\n",
      "Epoch 22/200\n",
      "600/600 [==============================] - 0s 391us/step - loss: 0.0755 - acc: 0.9850 - val_loss: 1.1628 - val_acc: 0.6850\n",
      "Epoch 23/200\n",
      "600/600 [==============================] - 0s 327us/step - loss: 0.0487 - acc: 0.9933 - val_loss: 1.2119 - val_acc: 0.6750\n",
      "Epoch 24/200\n",
      "600/600 [==============================] - 0s 321us/step - loss: 0.0365 - acc: 0.9950 - val_loss: 1.3264 - val_acc: 0.6700\n",
      "Epoch 25/200\n",
      "600/600 [==============================] - 0s 338us/step - loss: 0.0293 - acc: 0.9967 - val_loss: 1.3436 - val_acc: 0.6700\n",
      "Epoch 26/200\n",
      "600/600 [==============================] - 0s 332us/step - loss: 0.0294 - acc: 0.9983 - val_loss: 1.3190 - val_acc: 0.6800\n",
      "Epoch 27/200\n",
      "600/600 [==============================] - 0s 317us/step - loss: 0.0456 - acc: 0.9900 - val_loss: 1.3644 - val_acc: 0.6700\n",
      "Epoch 28/200\n",
      "600/600 [==============================] - 0s 285us/step - loss: 0.0651 - acc: 0.9833 - val_loss: 1.3910 - val_acc: 0.6500\n",
      "Epoch 29/200\n",
      "600/600 [==============================] - 0s 293us/step - loss: 0.0308 - acc: 0.9967 - val_loss: 1.4596 - val_acc: 0.6800\n",
      "Epoch 30/200\n",
      "600/600 [==============================] - 0s 322us/step - loss: 0.0229 - acc: 0.9983 - val_loss: 1.4132 - val_acc: 0.6750\n",
      "Epoch 31/200\n",
      "600/600 [==============================] - 0s 317us/step - loss: 0.0163 - acc: 0.9983 - val_loss: 1.4510 - val_acc: 0.6850\n",
      "Epoch 32/200\n",
      "600/600 [==============================] - 0s 330us/step - loss: 0.0182 - acc: 0.9967 - val_loss: 1.4226 - val_acc: 0.6800\n",
      "Epoch 33/200\n",
      "600/600 [==============================] - 0s 312us/step - loss: 0.0129 - acc: 0.9967 - val_loss: 1.4391 - val_acc: 0.6800\n",
      "Epoch 34/200\n",
      "600/600 [==============================] - 0s 321us/step - loss: 0.0093 - acc: 0.9983 - val_loss: 1.4423 - val_acc: 0.6650\n",
      "Epoch 35/200\n",
      "600/600 [==============================] - ETA: 0s - loss: 0.0182 - acc: 0.995 - 0s 293us/step - loss: 0.0148 - acc: 0.9967 - val_loss: 1.4467 - val_acc: 0.6550\n",
      "Epoch 36/200\n",
      "600/600 [==============================] - 0s 312us/step - loss: 0.0175 - acc: 0.9967 - val_loss: 1.4712 - val_acc: 0.6750\n",
      "Epoch 37/200\n",
      "600/600 [==============================] - 0s 335us/step - loss: 0.0109 - acc: 0.9967 - val_loss: 1.4729 - val_acc: 0.6600\n",
      "Epoch 38/200\n",
      "600/600 [==============================] - 0s 300us/step - loss: 0.0153 - acc: 0.9983 - val_loss: 1.5629 - val_acc: 0.6750\n",
      "Epoch 39/200\n",
      "600/600 [==============================] - 0s 301us/step - loss: 0.0108 - acc: 0.9983 - val_loss: 1.5039 - val_acc: 0.6650\n",
      "Epoch 40/200\n",
      "600/600 [==============================] - 0s 321us/step - loss: 0.0097 - acc: 0.9983 - val_loss: 1.4827 - val_acc: 0.6650\n",
      "Epoch 41/200\n",
      "600/600 [==============================] - 0s 350us/step - loss: 0.0072 - acc: 0.9967 - val_loss: 1.5380 - val_acc: 0.6600\n",
      "Epoch 42/200\n",
      "600/600 [==============================] - 0s 332us/step - loss: 0.0062 - acc: 0.9983 - val_loss: 1.5345 - val_acc: 0.6700\n",
      "Epoch 43/200\n",
      "600/600 [==============================] - 0s 325us/step - loss: 0.0083 - acc: 0.9983 - val_loss: 1.5562 - val_acc: 0.6750\n",
      "Epoch 44/200\n",
      "600/600 [==============================] - 0s 311us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 1.5269 - val_acc: 0.6750\n",
      "Epoch 45/200\n",
      "600/600 [==============================] - 0s 309us/step - loss: 0.0085 - acc: 0.9983 - val_loss: 1.6661 - val_acc: 0.6750\n",
      "Epoch 46/200\n",
      "600/600 [==============================] - 0s 304us/step - loss: 0.0172 - acc: 0.9967 - val_loss: 1.5626 - val_acc: 0.6800\n",
      "Epoch 47/200\n",
      "600/600 [==============================] - 0s 353us/step - loss: 0.0102 - acc: 0.9983 - val_loss: 1.5756 - val_acc: 0.6750\n",
      "Epoch 48/200\n",
      "600/600 [==============================] - 0s 295us/step - loss: 0.0092 - acc: 0.9983 - val_loss: 1.5538 - val_acc: 0.6850\n",
      "Epoch 49/200\n",
      "600/600 [==============================] - 0s 280us/step - loss: 0.0160 - acc: 0.9967 - val_loss: 1.6350 - val_acc: 0.6750\n",
      "Epoch 50/200\n",
      "600/600 [==============================] - 0s 331us/step - loss: 0.0051 - acc: 0.9983 - val_loss: 1.5803 - val_acc: 0.6700\n",
      "Epoch 51/200\n",
      "600/600 [==============================] - 0s 329us/step - loss: 0.0082 - acc: 0.9983 - val_loss: 1.6052 - val_acc: 0.6650\n",
      "Epoch 52/200\n",
      "600/600 [==============================] - 0s 332us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 1.5935 - val_acc: 0.6850\n",
      "Epoch 53/200\n",
      "600/600 [==============================] - 0s 319us/step - loss: 0.0100 - acc: 0.9967 - val_loss: 1.6593 - val_acc: 0.6750\n",
      "Epoch 54/200\n",
      "600/600 [==============================] - 0s 316us/step - loss: 0.0071 - acc: 0.9983 - val_loss: 1.6270 - val_acc: 0.6750\n",
      "Epoch 55/200\n",
      "600/600 [==============================] - 0s 306us/step - loss: 0.0043 - acc: 0.9983 - val_loss: 1.6425 - val_acc: 0.6750\n",
      "Epoch 56/200\n",
      "600/600 [==============================] - 0s 295us/step - loss: 0.0045 - acc: 0.9983 - val_loss: 1.6484 - val_acc: 0.6750\n",
      "Epoch 57/200\n",
      "600/600 [==============================] - 0s 350us/step - loss: 0.0053 - acc: 0.9983 - val_loss: 1.6618 - val_acc: 0.6650\n",
      "Epoch 58/200\n",
      "600/600 [==============================] - 0s 408us/step - loss: 0.0063 - acc: 0.9983 - val_loss: 1.6445 - val_acc: 0.6800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "600/600 [==============================] - 0s 343us/step - loss: 0.0074 - acc: 0.9983 - val_loss: 1.7099 - val_acc: 0.6800\n",
      "Epoch 60/200\n",
      "600/600 [==============================] - 0s 335us/step - loss: 0.0041 - acc: 0.9983 - val_loss: 1.6609 - val_acc: 0.6750\n",
      "Epoch 61/200\n",
      "600/600 [==============================] - 0s 319us/step - loss: 0.0050 - acc: 0.9967 - val_loss: 1.6653 - val_acc: 0.6750\n",
      "Epoch 62/200\n",
      "600/600 [==============================] - 0s 449us/step - loss: 0.0042 - acc: 0.9983 - val_loss: 1.6795 - val_acc: 0.6800\n",
      "Epoch 63/200\n",
      "600/600 [==============================] - 0s 340us/step - loss: 0.0057 - acc: 0.9967 - val_loss: 1.6770 - val_acc: 0.6800\n",
      "Epoch 64/200\n",
      "600/600 [==============================] - 0s 363us/step - loss: 0.0044 - acc: 0.9983 - val_loss: 1.6918 - val_acc: 0.6750\n",
      "Epoch 65/200\n",
      "600/600 [==============================] - 0s 343us/step - loss: 0.0061 - acc: 0.9967 - val_loss: 1.6989 - val_acc: 0.6800\n",
      "Epoch 66/200\n",
      "600/600 [==============================] - 0s 360us/step - loss: 0.0034 - acc: 0.9967 - val_loss: 1.6815 - val_acc: 0.6750\n",
      "Epoch 67/200\n",
      "600/600 [==============================] - 0s 447us/step - loss: 0.0048 - acc: 0.9983 - val_loss: 1.6959 - val_acc: 0.6750\n",
      "Epoch 68/200\n",
      "600/600 [==============================] - 0s 324us/step - loss: 0.0048 - acc: 0.9983 - val_loss: 1.7160 - val_acc: 0.6750\n",
      "Epoch 69/200\n",
      "600/600 [==============================] - 0s 348us/step - loss: 0.0052 - acc: 0.9967 - val_loss: 1.7128 - val_acc: 0.6750\n",
      "Epoch 70/200\n",
      "600/600 [==============================] - 0s 366us/step - loss: 0.0053 - acc: 0.9983 - val_loss: 1.6969 - val_acc: 0.6750\n",
      "Epoch 71/200\n",
      "600/600 [==============================] - 0s 363us/step - loss: 0.0064 - acc: 0.9967 - val_loss: 1.7392 - val_acc: 0.6800\n",
      "Epoch 72/200\n",
      "600/600 [==============================] - 0s 361us/step - loss: 0.0040 - acc: 0.9983 - val_loss: 1.7158 - val_acc: 0.6650\n",
      "Epoch 73/200\n",
      "600/600 [==============================] - 0s 307us/step - loss: 0.0035 - acc: 0.9983 - val_loss: 1.7144 - val_acc: 0.6700\n",
      "Epoch 74/200\n",
      "600/600 [==============================] - 0s 318us/step - loss: 0.0052 - acc: 0.9983 - val_loss: 1.7345 - val_acc: 0.6750\n",
      "Epoch 75/200\n",
      "600/600 [==============================] - 0s 337us/step - loss: 0.0040 - acc: 0.9983 - val_loss: 1.7447 - val_acc: 0.6650\n",
      "Epoch 76/200\n",
      "600/600 [==============================] - 0s 314us/step - loss: 0.0036 - acc: 0.9983 - val_loss: 1.7481 - val_acc: 0.6750\n",
      "Epoch 77/200\n",
      "600/600 [==============================] - 0s 327us/step - loss: 0.0057 - acc: 0.9983 - val_loss: 1.7674 - val_acc: 0.6750\n",
      "Epoch 78/200\n",
      "600/600 [==============================] - 0s 376us/step - loss: 0.0043 - acc: 0.9983 - val_loss: 1.7440 - val_acc: 0.6650\n",
      "Epoch 79/200\n",
      "600/600 [==============================] - 0s 382us/step - loss: 0.0037 - acc: 0.9983 - val_loss: 1.7490 - val_acc: 0.6700\n",
      "Epoch 80/200\n",
      "600/600 [==============================] - 0s 373us/step - loss: 0.0035 - acc: 0.9983 - val_loss: 1.7536 - val_acc: 0.6600\n",
      "Epoch 81/200\n",
      "600/600 [==============================] - 0s 371us/step - loss: 0.0059 - acc: 0.9967 - val_loss: 1.7871 - val_acc: 0.6800\n",
      "Epoch 82/200\n",
      "600/600 [==============================] - 0s 292us/step - loss: 0.0040 - acc: 0.9983 - val_loss: 1.7543 - val_acc: 0.6700\n",
      "Epoch 83/200\n",
      "600/600 [==============================] - 0s 350us/step - loss: 0.0051 - acc: 0.9983 - val_loss: 1.7625 - val_acc: 0.6800\n",
      "Epoch 84/200\n",
      "600/600 [==============================] - 0s 308us/step - loss: 0.0036 - acc: 0.9967 - val_loss: 1.7992 - val_acc: 0.6800\n",
      "Epoch 85/200\n",
      "600/600 [==============================] - 0s 325us/step - loss: 0.0048 - acc: 0.9983 - val_loss: 1.7855 - val_acc: 0.6700\n",
      "Epoch 86/200\n",
      "600/600 [==============================] - 0s 322us/step - loss: 0.0040 - acc: 0.9967 - val_loss: 1.7786 - val_acc: 0.6750\n",
      "Epoch 87/200\n",
      "600/600 [==============================] - 0s 338us/step - loss: 0.0048 - acc: 0.9983 - val_loss: 1.7852 - val_acc: 0.6750\n",
      "Epoch 88/200\n",
      "600/600 [==============================] - 0s 291us/step - loss: 0.0075 - acc: 0.9967 - val_loss: 1.7742 - val_acc: 0.6700\n",
      "Epoch 89/200\n",
      "600/600 [==============================] - 0s 330us/step - loss: 0.0035 - acc: 0.9983 - val_loss: 1.7697 - val_acc: 0.6750\n",
      "Epoch 90/200\n",
      "600/600 [==============================] - 0s 346us/step - loss: 0.0051 - acc: 0.9983 - val_loss: 1.8187 - val_acc: 0.6800\n",
      "Epoch 91/200\n",
      "600/600 [==============================] - 0s 317us/step - loss: 0.0076 - acc: 0.9983 - val_loss: 1.8441 - val_acc: 0.6700\n",
      "Epoch 92/200\n",
      "600/600 [==============================] - 0s 304us/step - loss: 0.0073 - acc: 0.9967 - val_loss: 1.7765 - val_acc: 0.6750\n",
      "Epoch 93/200\n",
      "600/600 [==============================] - 0s 325us/step - loss: 0.0042 - acc: 0.9983 - val_loss: 1.8577 - val_acc: 0.6750\n",
      "Epoch 94/200\n",
      "600/600 [==============================] - 0s 298us/step - loss: 0.0042 - acc: 0.9983 - val_loss: 1.8436 - val_acc: 0.6700\n",
      "Epoch 95/200\n",
      "600/600 [==============================] - 0s 280us/step - loss: 0.0032 - acc: 0.9967 - val_loss: 1.8173 - val_acc: 0.6800\n",
      "Epoch 96/200\n",
      "600/600 [==============================] - 0s 312us/step - loss: 0.0040 - acc: 0.9983 - val_loss: 1.8365 - val_acc: 0.6850\n",
      "Epoch 97/200\n",
      "600/600 [==============================] - 0s 319us/step - loss: 0.0057 - acc: 0.9967 - val_loss: 1.8710 - val_acc: 0.6800\n",
      "Epoch 98/200\n",
      "600/600 [==============================] - 0s 304us/step - loss: 0.0031 - acc: 0.9983 - val_loss: 1.8483 - val_acc: 0.6700\n",
      "Epoch 99/200\n",
      "600/600 [==============================] - 0s 301us/step - loss: 0.0034 - acc: 0.9983 - val_loss: 1.8468 - val_acc: 0.6700\n",
      "Epoch 100/200\n",
      "600/600 [==============================] - 0s 345us/step - loss: 0.0035 - acc: 0.9983 - val_loss: 1.8667 - val_acc: 0.6850\n",
      "Epoch 101/200\n",
      "600/600 [==============================] - 0s 355us/step - loss: 0.0036 - acc: 0.9983 - val_loss: 1.8728 - val_acc: 0.6750\n",
      "Epoch 102/200\n",
      "600/600 [==============================] - 0s 306us/step - loss: 0.0034 - acc: 0.9983 - val_loss: 1.8744 - val_acc: 0.6700\n",
      "Epoch 103/200\n",
      "600/600 [==============================] - 0s 311us/step - loss: 0.0029 - acc: 0.9983 - val_loss: 1.8698 - val_acc: 0.6750\n",
      "Epoch 104/200\n",
      "600/600 [==============================] - 0s 318us/step - loss: 0.0031 - acc: 0.9983 - val_loss: 1.8890 - val_acc: 0.6800\n",
      "Epoch 105/200\n",
      "600/600 [==============================] - 0s 277us/step - loss: 0.0031 - acc: 0.9967 - val_loss: 1.8947 - val_acc: 0.6750\n",
      "Epoch 106/200\n",
      "600/600 [==============================] - 0s 277us/step - loss: 0.0036 - acc: 0.9967 - val_loss: 1.8844 - val_acc: 0.6700\n",
      "Epoch 107/200\n",
      "600/600 [==============================] - 0s 288us/step - loss: 0.0033 - acc: 0.9967 - val_loss: 1.8925 - val_acc: 0.6700\n",
      "Epoch 108/200\n",
      "600/600 [==============================] - 0s 309us/step - loss: 0.0042 - acc: 0.9967 - val_loss: 1.9153 - val_acc: 0.6700\n",
      "Epoch 109/200\n",
      "600/600 [==============================] - 0s 312us/step - loss: 0.0039 - acc: 0.9967 - val_loss: 1.9058 - val_acc: 0.6700\n",
      "Epoch 110/200\n",
      "600/600 [==============================] - 0s 298us/step - loss: 0.0041 - acc: 0.9967 - val_loss: 1.9269 - val_acc: 0.6850\n",
      "Epoch 111/200\n",
      "600/600 [==============================] - 0s 278us/step - loss: 0.0029 - acc: 0.9983 - val_loss: 1.8989 - val_acc: 0.6850\n",
      "Epoch 112/200\n",
      "600/600 [==============================] - 0s 319us/step - loss: 0.0028 - acc: 0.9967 - val_loss: 1.8976 - val_acc: 0.6750\n",
      "Epoch 113/200\n",
      "600/600 [==============================] - 0s 280us/step - loss: 0.0035 - acc: 0.9967 - val_loss: 1.9105 - val_acc: 0.6800\n",
      "Epoch 114/200\n",
      "600/600 [==============================] - 0s 284us/step - loss: 0.0044 - acc: 0.9983 - val_loss: 1.9112 - val_acc: 0.6750\n",
      "Epoch 115/200\n",
      "600/600 [==============================] - 0s 301us/step - loss: 0.0030 - acc: 0.9983 - val_loss: 1.9383 - val_acc: 0.6900\n",
      "Epoch 116/200\n",
      "600/600 [==============================] - 0s 306us/step - loss: 0.0035 - acc: 0.9967 - val_loss: 1.9199 - val_acc: 0.6750\n",
      "Epoch 117/200\n",
      "600/600 [==============================] - 0s 295us/step - loss: 0.0029 - acc: 0.9983 - val_loss: 1.9308 - val_acc: 0.680000\n",
      "Epoch 118/200\n",
      "600/600 [==============================] - 0s 295us/step - loss: 0.0028 - acc: 0.9983 - val_loss: 1.9324 - val_acc: 0.6800\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 260us/step - loss: 0.0032 - acc: 0.9983 - val_loss: 1.9340 - val_acc: 0.6800\n",
      "Epoch 120/200\n",
      "600/600 [==============================] - 0s 285us/step - loss: 0.0032 - acc: 0.9967 - val_loss: 1.9476 - val_acc: 0.6800\n",
      "Epoch 121/200\n",
      "600/600 [==============================] - 0s 286us/step - loss: 0.0027 - acc: 0.9967 - val_loss: 1.9444 - val_acc: 0.6800\n",
      "Epoch 122/200\n",
      "600/600 [==============================] - 0s 293us/step - loss: 0.0026 - acc: 0.9983 - val_loss: 1.9545 - val_acc: 0.6750\n",
      "Epoch 123/200\n",
      "600/600 [==============================] - 0s 306us/step - loss: 0.0034 - acc: 0.9983 - val_loss: 1.9847 - val_acc: 0.6800\n",
      "Epoch 124/200\n",
      "600/600 [==============================] - 0s 336us/step - loss: 0.0026 - acc: 0.9983 - val_loss: 1.9743 - val_acc: 0.6750\n",
      "Epoch 125/200\n",
      "600/600 [==============================] - 0s 291us/step - loss: 0.0027 - acc: 0.9983 - val_loss: 1.9755 - val_acc: 0.6750\n",
      "Epoch 126/200\n",
      "600/600 [==============================] - 0s 309us/step - loss: 0.0033 - acc: 0.9983 - val_loss: 1.9707 - val_acc: 0.6800\n",
      "Epoch 127/200\n",
      "600/600 [==============================] - 0s 303us/step - loss: 0.0034 - acc: 0.9967 - val_loss: 1.9922 - val_acc: 0.6900\n",
      "Epoch 128/200\n",
      "600/600 [==============================] - 0s 389us/step - loss: 0.0034 - acc: 0.9983 - val_loss: 2.0011 - val_acc: 0.6850\n",
      "Epoch 129/200\n",
      "600/600 [==============================] - 0s 364us/step - loss: 0.0032 - acc: 0.9983 - val_loss: 1.9690 - val_acc: 0.6700\n",
      "Epoch 130/200\n",
      "600/600 [==============================] - 0s 374us/step - loss: 0.0029 - acc: 0.9983 - val_loss: 1.9791 - val_acc: 0.6750\n",
      "Epoch 131/200\n",
      "600/600 [==============================] - 0s 404us/step - loss: 0.0027 - acc: 0.9967 - val_loss: 1.9952 - val_acc: 0.6850\n",
      "Epoch 132/200\n",
      "600/600 [==============================] - 0s 376us/step - loss: 0.0035 - acc: 0.9983 - val_loss: 2.0207 - val_acc: 0.6850\n",
      "Epoch 133/200\n",
      "600/600 [==============================] - 0s 342us/step - loss: 0.0027 - acc: 0.9983 - val_loss: 1.9978 - val_acc: 0.6800\n",
      "Epoch 134/200\n",
      "600/600 [==============================] - 0s 290us/step - loss: 0.0032 - acc: 0.9983 - val_loss: 1.9849 - val_acc: 0.6800\n",
      "Epoch 135/200\n",
      "600/600 [==============================] - 0s 306us/step - loss: 0.0026 - acc: 0.9983 - val_loss: 2.0228 - val_acc: 0.6800\n",
      "Epoch 136/200\n",
      "600/600 [==============================] - 0s 347us/step - loss: 0.0030 - acc: 0.9983 - val_loss: 2.0094 - val_acc: 0.6800\n",
      "Epoch 137/200\n",
      "600/600 [==============================] - 0s 303us/step - loss: 0.0030 - acc: 0.9983 - val_loss: 2.0050 - val_acc: 0.6800\n",
      "Epoch 138/200\n",
      "600/600 [==============================] - 0s 357us/step - loss: 0.0031 - acc: 0.9967 - val_loss: 2.0075 - val_acc: 0.6850\n",
      "Epoch 139/200\n",
      "600/600 [==============================] - 0s 312us/step - loss: 0.0031 - acc: 0.9967 - val_loss: 2.0236 - val_acc: 0.6850\n",
      "Epoch 140/200\n",
      "600/600 [==============================] - 0s 301us/step - loss: 0.0029 - acc: 0.9983 - val_loss: 2.0023 - val_acc: 0.6750\n",
      "Epoch 141/200\n",
      "600/600 [==============================] - 0s 332us/step - loss: 0.0029 - acc: 0.9967 - val_loss: 2.0194 - val_acc: 0.6850\n",
      "Epoch 142/200\n",
      "600/600 [==============================] - 0s 358us/step - loss: 0.0029 - acc: 0.9983 - val_loss: 2.0151 - val_acc: 0.6850\n",
      "Epoch 143/200\n",
      "600/600 [==============================] - 0s 287us/step - loss: 0.0032 - acc: 0.9983 - val_loss: 2.0265 - val_acc: 0.6850\n",
      "Epoch 144/200\n",
      "600/600 [==============================] - 0s 301us/step - loss: 0.0027 - acc: 0.9983 - val_loss: 2.0587 - val_acc: 0.6800\n",
      "Epoch 145/200\n",
      "600/600 [==============================] - 0s 338us/step - loss: 0.0033 - acc: 0.9983 - val_loss: 2.0852 - val_acc: 0.6800\n",
      "Epoch 146/200\n",
      "600/600 [==============================] - 0s 323us/step - loss: 0.0027 - acc: 0.9983 - val_loss: 2.0416 - val_acc: 0.6750\n",
      "Epoch 147/200\n",
      "600/600 [==============================] - 0s 295us/step - loss: 0.0033 - acc: 0.9983 - val_loss: 2.0214 - val_acc: 0.6800\n",
      "Epoch 148/200\n",
      "600/600 [==============================] - 0s 346us/step - loss: 0.0026 - acc: 0.9983 - val_loss: 2.0430 - val_acc: 0.6850\n",
      "Epoch 149/200\n",
      "600/600 [==============================] - 0s 350us/step - loss: 0.0026 - acc: 0.9967 - val_loss: 2.0579 - val_acc: 0.6850\n",
      "Epoch 150/200\n",
      "600/600 [==============================] - 0s 320us/step - loss: 0.0029 - acc: 0.9983 - val_loss: 2.0751 - val_acc: 0.6850\n",
      "Epoch 151/200\n",
      "600/600 [==============================] - 0s 314us/step - loss: 0.0025 - acc: 0.9983 - val_loss: 2.0580 - val_acc: 0.6750\n",
      "Epoch 152/200\n",
      "600/600 [==============================] - 0s 315us/step - loss: 0.0030 - acc: 0.9983 - val_loss: 2.0658 - val_acc: 0.6800\n",
      "Epoch 153/200\n",
      "600/600 [==============================] - 0s 359us/step - loss: 0.0028 - acc: 0.9983 - val_loss: 2.0764 - val_acc: 0.6850\n",
      "Epoch 154/200\n",
      "600/600 [==============================] - 0s 306us/step - loss: 0.0032 - acc: 0.9983 - val_loss: 2.1015 - val_acc: 0.6850\n",
      "Epoch 155/200\n",
      "600/600 [==============================] - 0s 318us/step - loss: 0.0028 - acc: 0.9983 - val_loss: 2.0708 - val_acc: 0.6800\n",
      "Epoch 156/200\n",
      "600/600 [==============================] - 0s 314us/step - loss: 0.0030 - acc: 0.9967 - val_loss: 2.0582 - val_acc: 0.6800\n",
      "Epoch 157/200\n",
      "600/600 [==============================] - 0s 307us/step - loss: 0.0032 - acc: 0.9983 - val_loss: 2.0507 - val_acc: 0.6900\n",
      "Epoch 158/200\n",
      "600/600 [==============================] - 0s 330us/step - loss: 0.0028 - acc: 0.9983 - val_loss: 2.0744 - val_acc: 0.6850\n",
      "Epoch 159/200\n",
      "600/600 [==============================] - 0s 311us/step - loss: 0.0029 - acc: 0.9967 - val_loss: 2.0802 - val_acc: 0.6850\n",
      "Epoch 160/200\n",
      "600/600 [==============================] - 0s 333us/step - loss: 0.0027 - acc: 0.9983 - val_loss: 2.0938 - val_acc: 0.6800\n",
      "Epoch 161/200\n",
      "600/600 [==============================] - 0s 388us/step - loss: 0.0027 - acc: 0.9983 - val_loss: 2.0930 - val_acc: 0.6850\n",
      "Epoch 162/200\n",
      "600/600 [==============================] - 0s 335us/step - loss: 0.0033 - acc: 0.9967 - val_loss: 2.0769 - val_acc: 0.6800\n",
      "Epoch 163/200\n",
      "600/600 [==============================] - 0s 292us/step - loss: 0.0037 - acc: 0.9967 - val_loss: 2.0985 - val_acc: 0.6850\n",
      "Epoch 164/200\n",
      "600/600 [==============================] - 0s 313us/step - loss: 0.0027 - acc: 0.9967 - val_loss: 2.0698 - val_acc: 0.6800\n",
      "Epoch 165/200\n",
      "600/600 [==============================] - 0s 337us/step - loss: 0.0031 - acc: 0.9967 - val_loss: 2.0645 - val_acc: 0.6900\n",
      "Epoch 166/200\n",
      "600/600 [==============================] - 0s 329us/step - loss: 0.0025 - acc: 0.9983 - val_loss: 2.1083 - val_acc: 0.6850\n",
      "Epoch 167/200\n",
      "600/600 [==============================] - 0s 354us/step - loss: 0.0025 - acc: 0.9983 - val_loss: 2.1069 - val_acc: 0.6850\n",
      "Epoch 168/200\n",
      "600/600 [==============================] - 0s 323us/step - loss: 0.0027 - acc: 0.9983 - val_loss: 2.1050 - val_acc: 0.6850\n",
      "Epoch 169/200\n",
      "600/600 [==============================] - 0s 304us/step - loss: 0.0026 - acc: 0.9983 - val_loss: 2.1074 - val_acc: 0.6850\n",
      "Epoch 170/200\n",
      "600/600 [==============================] - 0s 289us/step - loss: 0.0030 - acc: 0.9983 - val_loss: 2.1118 - val_acc: 0.6800\n",
      "Epoch 171/200\n",
      "600/600 [==============================] - 0s 291us/step - loss: 0.0027 - acc: 0.9967 - val_loss: 2.1228 - val_acc: 0.6850\n",
      "Epoch 172/200\n",
      "600/600 [==============================] - 0s 295us/step - loss: 0.0025 - acc: 0.9983 - val_loss: 2.1211 - val_acc: 0.6850\n",
      "Epoch 173/200\n",
      "600/600 [==============================] - 0s 316us/step - loss: 0.0030 - acc: 0.9983 - val_loss: 2.1248 - val_acc: 0.6850\n",
      "Epoch 174/200\n",
      "600/600 [==============================] - 0s 321us/step - loss: 0.0042 - acc: 0.9967 - val_loss: 2.0921 - val_acc: 0.6750\n",
      "Epoch 175/200\n",
      "600/600 [==============================] - 0s 299us/step - loss: 0.0031 - acc: 0.9967 - val_loss: 2.1277 - val_acc: 0.6850\n",
      "Epoch 176/200\n",
      "600/600 [==============================] - 0s 299us/step - loss: 0.0028 - acc: 0.9983 - val_loss: 2.0906 - val_acc: 0.6800\n",
      "Epoch 177/200\n",
      "600/600 [==============================] - 0s 301us/step - loss: 0.0034 - acc: 0.9983 - val_loss: 2.0702 - val_acc: 0.6900\n",
      "Epoch 178/200\n",
      "600/600 [==============================] - 0s 330us/step - loss: 0.0029 - acc: 0.9983 - val_loss: 2.1153 - val_acc: 0.6850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/200\n",
      "600/600 [==============================] - 0s 278us/step - loss: 0.0030 - acc: 0.9967 - val_loss: 2.1198 - val_acc: 0.6850\n",
      "Epoch 180/200\n",
      "600/600 [==============================] - 0s 306us/step - loss: 0.0027 - acc: 0.9967 - val_loss: 2.1297 - val_acc: 0.6900\n",
      "Epoch 181/200\n",
      "600/600 [==============================] - 0s 326us/step - loss: 0.0035 - acc: 0.9983 - val_loss: 2.1635 - val_acc: 0.6950\n",
      "Epoch 182/200\n",
      "600/600 [==============================] - 0s 340us/step - loss: 0.0028 - acc: 0.9967 - val_loss: 2.1035 - val_acc: 0.6900\n",
      "Epoch 183/200\n",
      "600/600 [==============================] - 0s 342us/step - loss: 0.0029 - acc: 0.9983 - val_loss: 2.1051 - val_acc: 0.6950\n",
      "Epoch 184/200\n",
      "600/600 [==============================] - 0s 306us/step - loss: 0.0027 - acc: 0.9983 - val_loss: 2.1403 - val_acc: 0.6850\n",
      "Epoch 185/200\n",
      "600/600 [==============================] - 0s 321us/step - loss: 0.0027 - acc: 0.9983 - val_loss: 2.1575 - val_acc: 0.6900\n",
      "Epoch 186/200\n",
      "600/600 [==============================] - ETA: 0s - loss: 0.0034 - acc: 0.9978   - 0s 313us/step - loss: 0.0025 - acc: 0.9983 - val_loss: 2.1746 - val_acc: 0.6900\n",
      "Epoch 187/200\n",
      "600/600 [==============================] - 0s 323us/step - loss: 0.0033 - acc: 0.9983 - val_loss: 2.1717 - val_acc: 0.6850\n",
      "Epoch 188/200\n",
      "600/600 [==============================] - 0s 293us/step - loss: 0.0024 - acc: 0.9983 - val_loss: 2.1480 - val_acc: 0.6800\n",
      "Epoch 189/200\n",
      "600/600 [==============================] - 0s 369us/step - loss: 0.0031 - acc: 0.9967 - val_loss: 2.1553 - val_acc: 0.6900\n",
      "Epoch 190/200\n",
      "600/600 [==============================] - 0s 303us/step - loss: 0.0028 - acc: 0.9967 - val_loss: 2.1511 - val_acc: 0.6950\n",
      "Epoch 191/200\n",
      "600/600 [==============================] - 0s 286us/step - loss: 0.0032 - acc: 0.9983 - val_loss: 2.1361 - val_acc: 0.6950\n",
      "Epoch 192/200\n",
      "600/600 [==============================] - 0s 337us/step - loss: 0.0035 - acc: 0.9967 - val_loss: 2.1716 - val_acc: 0.6900\n",
      "Epoch 193/200\n",
      "600/600 [==============================] - 0s 325us/step - loss: 0.0026 - acc: 0.9983 - val_loss: 2.1541 - val_acc: 0.6750\n",
      "Epoch 194/200\n",
      "600/600 [==============================] - 0s 347us/step - loss: 0.0029 - acc: 0.9967 - val_loss: 2.1618 - val_acc: 0.6950\n",
      "Epoch 195/200\n",
      "600/600 [==============================] - 0s 314us/step - loss: 0.0024 - acc: 0.9983 - val_loss: 2.1318 - val_acc: 0.6950\n",
      "Epoch 196/200\n",
      "600/600 [==============================] - 0s 322us/step - loss: 0.0026 - acc: 0.9983 - val_loss: 2.1544 - val_acc: 0.7000\n",
      "Epoch 197/200\n",
      "600/600 [==============================] - 0s 350us/step - loss: 0.0027 - acc: 0.9983 - val_loss: 2.1763 - val_acc: 0.6950\n",
      "Epoch 198/200\n",
      "600/600 [==============================] - 0s 334us/step - loss: 0.0027 - acc: 0.9983 - val_loss: 2.1879 - val_acc: 0.7000\n",
      "Epoch 199/200\n",
      "600/600 [==============================] - 0s 371us/step - loss: 0.0025 - acc: 0.9983 - val_loss: 2.2098 - val_acc: 0.6950\n",
      "Epoch 200/200\n",
      "600/600 [==============================] - 0s 369us/step - loss: 0.0027 - acc: 0.9983 - val_loss: 2.2088 - val_acc: 0.7000\n",
      "200/200 [==============================] - 0s 139us/step\n",
      "Test loss: 2.3894962787628176\n",
      "Test accuracy: 0.63\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=200,\n",
    "          batch_size=32,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', results[0])\n",
    "print('Test accuracy:', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tkinter\n",
    "from tkinter import messagebox\n",
    "from tkinter import filedialog\n",
    "from PIL import ImageTk,Image\n",
    "from tkinter import *\n",
    "\n",
    "\n",
    "main_win = tkinter.Tk()\n",
    "main_win.geometry(\"1000x500\")\n",
    "main_win.sourceFile = ''\n",
    "w = Label(main_win, text=\"AUDIO GENRE CLASSIFICATION\", font=(\"Helvetica\", 25))\n",
    "w.pack()\n",
    "\n",
    "\n",
    "\n",
    "def chooseFile():\n",
    "    main_win.sourceFile = filedialog.askopenfilename(parent=main_win, initialdir= \"/\", title='Please select a directory')\n",
    "\n",
    "b_chooseFile = tkinter.Button(main_win, text = \"Choose File\", width = 20, height = 3, command = chooseFile)\n",
    "b_chooseFile.place(x = 400,y = 150)\n",
    "b_chooseFile.width = 100\n",
    "\n",
    "\n",
    "\n",
    "def task():  \n",
    "    cmap = plt.get_cmap('inferno')\n",
    "    songname1 = f'{main_win.sourceFile}'\n",
    "    y1, sr1 = librosa.load(songname1, mono=True, duration=30)\n",
    "    plt.specgram(y1, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "    plt.axis('off');\n",
    "    plt.clf()\n",
    "\n",
    "    header = 'chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "    for i in range(1, 21):\n",
    "        header += f' mfcc{i}'\n",
    "    header = header.split()\n",
    "    file = open('data1.csv', 'w', newline='')\n",
    "    with file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y1, sr=sr1)\n",
    "    rmse = librosa.feature.rmse(y=y1)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y1, sr=sr1)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y1, sr=sr1)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y1, sr=sr1)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y1)\n",
    "    mfcc = librosa.feature.mfcc(y=y1, sr=sr1)\n",
    "    to_append = f'{np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    "    for e in mfcc:\n",
    "        to_append += f' {np.mean(e)}'\n",
    "    file = open('data1.csv', 'a', newline='')\n",
    "    with file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(to_append.split())\n",
    "    data1 = pd.read_csv('data1.csv')\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n",
    "    X1= scaler.transform(data1)\n",
    "    predictions=model.predict(X1)\n",
    "    if(np.argmax(predictions[0])==0):\n",
    "        out = Label(main_win, text=\"---BLUES-----\", font=(\"Helvetica\", 25))\n",
    "        out.place(x = 400,y = 350)\n",
    "    if(np.argmax(predictions[0])==1):\n",
    "        out = Label(main_win, text=\"--CLASSICAL--\", font=(\"Helvetica\", 25))\n",
    "        out.place(x = 400,y = 350)\n",
    "    if(np.argmax(predictions[0])==2):\n",
    "        out = Label(main_win, text=\"--COUNTRY----\", font=(\"Helvetica\", 25))\n",
    "        out.place(x = 400,y = 350)\n",
    "    if(np.argmax(predictions[0])==3):\n",
    "        out = Label(main_win, text=\"----DISCO----\", font=(\"Helvetica\", 25))\n",
    "        out.place(x = 400,y = 350)\n",
    "    if(np.argmax(predictions[0])==4):\n",
    "        out = Label(main_win, text=\"---HIP-HOP---\", font=(\"Helvetica\", 25))\n",
    "        out.place(x = 400,y = 350)\n",
    "    if(np.argmax(predictions[0])==5):\n",
    "        out = Label(main_win, text=\"----JAZZ----\", font=(\"Helvetica\", 25))\n",
    "        out.place(x = 400,y = 350)\n",
    "    if(np.argmax(predictions[0])==6):\n",
    "        out = Label(main_win, text=\"---METAL---\", font=(\"Helvetica\", 25))\n",
    "        out.place(x = 400,y = 350)\n",
    "    if(np.argmax(predictions[0])==7):\n",
    "        out = Label(main_win, text=\"----POP----\", font=(\"Helvetica\", 25))\n",
    "        out.place(x = 400,y = 350)\n",
    "    if(np.argmax(predictions[0])==8):\n",
    "        out = Label(main_win, text=\"--REGGAE--\", font=(\"Helvetica\", 25))\n",
    "        out.place(x = 400,y = 350)\n",
    "    if(np.argmax(predictions[0])==9):\n",
    "        out = Label(main_win, text=\"---ROCK---\", font=(\"Helvetica\", 25))\n",
    "        out.place(x = 400,y = 350)\n",
    "\n",
    "predict = tkinter.Button(main_win, text = \"Predict\", width = 20, height = 3, command = task)\n",
    "predict.place(x = 400,y = 250)\n",
    "predict.width = 100\n",
    "\n",
    "main_win.mainloop()\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:             \n",
    "     json_file.write(model_json) \n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 4, 0, 2, 6, 6, 3, 9, 6, 7, 9, 7, 9, 2, 1, 3, 1, 2, 7, 8, 3, 5,\n",
       "       7, 7, 6, 8, 5, 5, 9, 0, 9, 4, 7, 9, 0, 6, 2, 5, 5, 1, 1, 3, 7, 6,\n",
       "       3, 6, 1, 3, 7, 0, 8, 0, 7, 4, 7, 0, 1, 5, 3, 7, 1, 9, 9, 8, 5, 8,\n",
       "       4, 0, 4, 4, 0, 6, 2, 5, 1, 9, 3, 5, 1, 2, 8, 3, 9, 9, 8, 4, 2, 8,\n",
       "       4, 8, 7, 3, 4, 9, 4, 2, 8, 0, 4, 4, 4, 2, 1, 0, 3, 2, 9, 4, 6, 0,\n",
       "       9, 8, 4, 6, 4, 7, 3, 6, 1, 6, 3, 5, 6, 0, 0, 6, 7, 3, 7, 5, 0, 6,\n",
       "       7, 4, 7, 9, 4, 9, 1, 3, 2, 7, 1, 9, 5, 6, 7, 5, 2, 7, 9, 7, 4, 0,\n",
       "       1, 9, 3, 7, 4, 1, 1, 1, 2, 5, 3, 1, 7, 9, 2, 7, 1, 3, 8, 8, 8, 4,\n",
       "       4, 3, 1, 3, 3, 2, 1, 4, 9, 1, 3, 3, 7, 0, 6, 1, 3, 4, 8, 8, 6, 2,\n",
       "       8, 0, 8, 6, 9, 0, 8, 7, 5, 6, 8, 4, 4, 6, 5, 0, 7, 6, 7, 9, 9, 1,\n",
       "       2, 2, 9, 4, 2, 9, 5, 0, 3, 5, 2, 1, 1, 3, 1, 8, 8, 3, 4, 6, 5, 6,\n",
       "       4, 0, 7, 1, 9, 4, 5, 4, 6, 6, 4, 2, 0, 6, 6, 1, 4, 7, 6, 8, 2, 4,\n",
       "       9, 2, 2, 6, 6, 5, 4, 6, 1, 2, 1, 5, 4, 8, 2, 5, 5, 6, 7, 7, 9, 1,\n",
       "       6, 0, 8, 1, 2, 0, 2, 0, 7, 7, 7, 0, 4, 5, 2, 7, 7, 7, 4, 0, 4, 1,\n",
       "       0, 2, 5, 2, 2, 5, 6, 3, 4, 7, 1, 1, 4, 6, 5, 4, 7, 1, 0, 8, 3, 5,\n",
       "       6, 2, 3, 3, 6, 6, 8, 6, 5, 6, 7, 7, 5, 6, 2, 9, 0, 0, 9, 8, 4, 0,\n",
       "       2, 0, 2, 9, 6, 8, 3, 2, 8, 3, 9, 0, 3, 1, 8, 3, 9, 4, 0, 4, 7, 2,\n",
       "       5, 5, 3, 9, 0, 5, 0, 9, 3, 9, 4, 5, 7, 9, 0, 1, 0, 2, 9, 5, 9, 2,\n",
       "       2, 7, 3, 1, 3, 8, 2, 0, 1, 6, 4, 9, 0, 9, 5, 1, 8, 8, 8, 6, 8, 6,\n",
       "       9, 6, 7, 4, 0, 9, 1, 1, 0, 9, 8, 5, 9, 8, 5, 8, 5, 8, 7, 9, 7, 1,\n",
       "       8, 5, 9, 1, 7, 9, 3, 0, 6, 6, 4, 6, 0, 1, 1, 0, 6, 4, 9, 0, 0, 1,\n",
       "       9, 7, 3, 6, 6, 7, 2, 7, 7, 4, 9, 0, 8, 1, 4, 5, 3, 9, 8, 6, 9, 0,\n",
       "       2, 1, 0, 3, 3, 3, 7, 0, 4, 3, 0, 1, 5, 2, 5, 0, 8, 3, 5, 1, 1, 5,\n",
       "       8, 3, 5, 6, 8, 7, 2, 7, 2, 1, 0, 5, 7, 0, 8, 8, 2, 3, 5, 3, 5, 5,\n",
       "       7, 2, 9, 0, 5, 7, 7, 2, 1, 5, 4, 7, 7, 8, 5, 0, 2, 9, 4, 5, 6, 0,\n",
       "       9, 8, 1, 9, 4, 3, 4, 1, 1, 3, 7, 1, 8, 2, 8, 8, 0, 9, 2, 7, 1, 1,\n",
       "       8, 5, 4, 0, 3, 6, 9, 2, 5, 6, 8, 2, 3, 5, 6, 8, 1, 7, 7, 5, 3, 7,\n",
       "       5, 4, 2, 2, 9, 2, 9, 5, 8, 9, 9, 0, 8, 9, 2, 3, 0, 7, 4, 1, 3, 5,\n",
       "       2, 2, 2, 3, 9, 4, 4, 3, 6, 3, 4, 5, 4, 1, 9, 1, 0, 3, 2, 0, 2, 5,\n",
       "       5, 3, 2, 8, 2, 8, 6, 2, 9, 4, 9, 7, 2, 9, 9, 1, 1, 0, 2, 4, 1, 3,\n",
       "       9, 8, 5, 3, 7, 5, 9, 6, 7, 7, 1, 2, 3, 8, 7, 5, 8, 4, 7, 7, 1, 9,\n",
       "       3, 6, 0, 4, 6, 0, 3, 1, 2, 8, 2, 0, 4, 5, 5, 3, 7, 5, 4, 1, 0, 1,\n",
       "       7, 9, 6, 9, 7, 3, 4, 3, 1, 0, 9, 2, 4, 4, 8, 8, 4, 8, 0, 6, 6, 7,\n",
       "       5, 4, 5, 4, 6, 8, 3, 6, 0, 6, 3, 0, 1, 1, 3, 5, 4, 8, 8, 3, 6, 6,\n",
       "       7, 0, 5, 1, 8, 6, 8, 0, 8, 7, 9, 7, 3, 0, 0, 5, 8, 3, 6, 7, 6, 7,\n",
       "       9, 9, 2, 1, 7, 6, 6, 7, 4, 0, 7, 1, 3, 2, 1, 5, 7, 1, 5, 1, 0, 1,\n",
       "       0, 7, 9, 2, 0, 9, 8, 5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
